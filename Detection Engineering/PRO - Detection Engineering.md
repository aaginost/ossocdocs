## Purpose
Detection Engineering (DE), also known as Content Development, is a critical function within a mature cybersecurity defense team. Security Operations Centers (SOCs) rely on tools such as Security Information and Event Management (SIEM) and Endpoint Detection and Response (EDR) to continuously monitor the environment and respond to potential threats. While these tools typically come equipped with out-of-the-box detection rules, these default configurations are often generic and may not fully align with an organization’s unique risk profile, operational landscape, or evolving threat landscape.

To enhance the effectiveness of security monitoring, detection rules must be continuously tuned and optimized to reflect an organization’s specific environment. Additionally, as new vulnerabilities emerge and attacker techniques evolve, security teams must develop and deploy custom detection content to ensure comprehensive threat coverage. Maintaining the relevance and efficacy of SIEM and EDR tools requires an ongoing lifecycle of detection development, refinement, and adaptation to stay ahead of emerging threats.

## Scope
This process applies to detection engineering done by SOC engineers with the support of other internal and external teams.  This process is intended to be applied to security monitoring and response tools managed and maintained by the SOC

## Roles and Responsibilities

| Role                                 | Responsibility                                                                                                                                                                                                                                                                                                                                                                                                  |
| ------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| SOC Analyst                          | Monitor the operational environment and respond to alerts generated by detections.<br>Propose acceptance criteria for new detections<br>Evaluate detections for efficacy and tuning requests<br>Propose new detections based on operational observations<br>Perform QA/QC to evaluate the investigative work of Analysts and to identify gaps in process documentation or runbooks                              |
| Detection Engineer                   | Manage and maintain the Backlog<br>Maintain the Detection Catalog Track detection development in the detection tracking document<br>Develop and deploy detections to test and production environments<br>Develop training and runbooks for new detections<br>Respond to tuning requests<br>Propose new detections for the Backlog.<br>Tracks metrics for detection development and Detection Catalog evolution. |
| SOC Leadership                       | Evaluated efficacy of new detections.<br>Authorizes migration of detection rules to production.<br>Reviews and evaluates metrics.                                                                                                                                                                                                                                                                               |
| Cyber Threat Intelligence (CTI) Team | Proposes new detections for development.<br>Attends weekly Detection Engineering meetings.                                                                                                                                                                                                                                                                                                                      |
| Threat Hunt Team                     | Proposes new detections for development.<br>Attends weekly Detection Engineering meetings.                                                                                                                                                                                                                                                                                                                      |
| Red/Purple Team                      | Proposes new detections for development.<br>Attends weekly Detection Engineering meetings.                                                                                                                                                                                                                                                                                                                      |
## Process Steps
### **1. Backlog Maintenance, Grooming, Prioritization, and Review**

- A **Detection Catalog** is maintained, listing all active, proposed, and deprecated detections.
	- This process should recognize incentives for the detection engineering team to produce detections quickly and there may need to be a counter-incentive to quick or easy detections.
	- The SOC is incentivized to create detections that are easy to action and have a high true positive rate
	- Security leadership may accept detections with low fidelity given the impact of a true positive (think a detection that rarely fires, but when it does is an indication of a severe incident.)
- New detection requests and enhancements are logged in a backlog.
- A **weekly Detection Engineering meeting** is held to review backlog items, assess urgency, and prioritize based on:
    - Business and security risks
    - Compliance requirements
    - Recent threat intelligence reports
    - Feedback from SOC Analysts
    - Input from Cyber Threat Intelligence teams about emerging threat actors and TTPs
    - Input from the Threat Hunt team about recent hunts
    - Input from Red and Purple Teams gleaned from operations
- Detections move forward in the lifecycle based on priority and feasibility.
- Evaluation of progression should be based on scoring across three axes:
	- Scope - the overall risk reduction for the new detection should be considered.  Detections that apply to the majority of endpoints, or the largest volume of signal should be ranked higher.
	- Complexity - It is worth considering the difficulty of implementation and the level of effort required to create an alert.
	- Impact - The likelihood of a scenario being detected along with the relative risk of the behavior.  For instance, detecting a successful brute force attack will probably be a more common scenario than an attempt to dump LSASS, but the later may be more important for an organizational detection and response effort.

### **2. Detection Development**

- The Detection Engineer drafts the detection logic based on:
    - Security use case requirements
    - Threat models and attack techniques (e.g., MITRE ATT&CK)
    - Logs, telemetry, and existing security tooling
- Detection logic is implemented using appropriate query languages (e.g., SIEM query languages, EDR detection formats).
- The **Detection Catalog** is updated with:
    - Rule name and purpose
    - Authors and implementation details
    - Rule logic and expected behavior

### **3. Detection Testing and Review**

- The detection rule undergoes initial functional testing in a controlled environment.
- Detection rules can be evaluated against historical log sources, doing a retrospective analysis using the detection rule.
- Test scripts or simulated attack scenarios are executed to validate detection triggers.
	- These scripts or steps for attach should be noted in the **Detection Catalog** entry for the rule in order to reproduce and automate testing.
- The Detection Engineering team reviews test results to ensure:
    - Detection accuracy (reducing false positives/negatives)
    - Performance impact on security tools
    - Compliance with security policy and legal requirements

### **4. Detection Acceptance, Testing, Training, and Documentation**

- Once testing is complete, the detection rule is proposed for acceptance in the **weekly Detection Engineering meeting**.
- SOC Leadership evaluates the efficacy of the rule and alignment to business goals and risk tolerances.  Consideration should be given to available SOC bandwidth and relative volumetric impact of the new detection on the workload of the SOC.
- SOC Analysts are trained on the new rule, including:
    - Expected alerts and response actions
    - Explicit playbooks for the detection should be written and added to the playbook catalog.
    - Investigation and triage guidelines
- Documentation is updated, including:
    - Detection logic and purpose
    - Implementation details and configurations
    - Associated response procedures

### **5. Migration to Production**

- After approval, the detection rule is deployed into the production SIEM/EDR environment.
- The Detection Engineer ensures:
    - Proper deployment with minimal impact on existing detections
    - Verification that alerts are functioning as expected
- A monitoring period is established to detect potential misconfigurations or unexpected alert volumes.
- SOC Analysts should be informed of the change following [[PRO - Change Notifications]]

### **6. Ongoing Evaluation of Production Rules**

- The Detection Engineering team continuously reviews detections based on:
    - SOC feedback (effectiveness of alerts)
    - Changes in attacker behavior or new threat intelligence
    - Operational metrics (false positives, false negatives, alert volume)
- Rules that require refinement are flagged for tuning.

### **7. Tuning and/or Deprecation Candidacy**

- Detections are adjusted to **reduce false positives** or improve accuracy.
- Deprecated rules are removed if they:
    - Are no longer relevant due to system changes or evolving threats
    - Have been replaced with improved versions
    - Generate excessive false positives with minimal security value
- Deprecation decisions are finalized in the weekly Detection Engineering meeting and documented in the **Detection Catalog**.